{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "walker_60_suwon = pd.read_csv(\"D:\\\\jupyter_proj\\\\walker_60_suwon.csv\")\n",
    "\n",
    "for i in range(len(walker_60_suwon)):\n",
    "    if walker_60_suwon['도로심각도지수basic'][i] < 0.1168:\n",
    "        walker_60_suwon['도로심각도지수basic'][i] = 0\n",
    "    else:\n",
    "        walker_60_suwon['도로심각도지수basic'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(walker_60_suwon[walker_60_suwon['도로심각도지수basic'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_가해자성별 = pd.get_dummies(walker_60_suwon['가해자성별'], prefix='가해자성별')\n",
    "dummy_교차로형태 = pd.get_dummies(walker_60_suwon['교차로형태'], prefix='교차로형태')\n",
    "dummy_기상상태 = pd.get_dummies(walker_60_suwon['기상상태'], prefix='기상상태')\n",
    "dummy_노면상태 = pd.get_dummies(walker_60_suwon['노면상태'], prefix='노면상태')\n",
    "dummy_노면상태_대분류 = pd.get_dummies(walker_60_suwon['노면상태_대분류'], prefix='노면상태_대분류')\n",
    "dummy_노인보호구역 = pd.get_dummies(walker_60_suwon['노인보호구역'], prefix='노인보호구역')\n",
    "dummy_당사자종별가해자 = pd.get_dummies(walker_60_suwon['당사자종별가해자'], prefix='당사자종별가해자')\n",
    "dummy_당사자종별피해자 = pd.get_dummies(walker_60_suwon['당사자종별피해자'], prefix='당사자종별피해자')\n",
    "dummy_도로선형 = pd.get_dummies(walker_60_suwon['도로선형'], prefix='도로선형')\n",
    "dummy_도로선형_대분류 = pd.get_dummies(walker_60_suwon['도로선형_대분류'], prefix='도로선형_대분류')\n",
    "dummy_도로선형_중분류 = pd.get_dummies(walker_60_suwon['도로선형_중분류'], prefix='도로선형_중분류')\n",
    "dummy_도로종류 = pd.get_dummies(walker_60_suwon['도로종류'], prefix='도로종류')\n",
    "dummy_도로형태 = pd.get_dummies(walker_60_suwon['도로형태'], prefix='도로형태')\n",
    "dummy_법규위반가해자 = pd.get_dummies(walker_60_suwon['법규위반가해자'], prefix='법규위반가해자')\n",
    "dummy_보호장구가해자_대분류 = pd.get_dummies(walker_60_suwon['보호장구가해자_대분류'], prefix='보호장구가해자_대분류')\n",
    "dummy_보호장구피해자_대분류 = pd.get_dummies(walker_60_suwon['보호장구피해자_대분류'], prefix='보호장구피해자_대분류')\n",
    "dummy_사고유형 = pd.get_dummies(walker_60_suwon['사고유형'], prefix='사고유형')\n",
    "dummy_사고유형_대분류 = pd.get_dummies(walker_60_suwon['사고유형_대분류'], prefix='사고유형_대분류')\n",
    "dummy_어린이보호구역 = pd.get_dummies(walker_60_suwon['어린이보호구역'], prefix='어린이보호구역')\n",
    "dummy_요일 = pd.get_dummies(walker_60_suwon['요일'], prefix='요일')\n",
    "dummy_주야 = pd.get_dummies(walker_60_suwon['주야'], prefix='주야')\n",
    "dummy_차량용도가해자 = pd.get_dummies(walker_60_suwon['차량용도가해자'], prefix='차량용도가해자')\n",
    "dummy_차량용도가해자_대분류 = pd.get_dummies(walker_60_suwon['차량용도가해자_대분류'], prefix='차량용도가해자_대분류')\n",
    "dummy_차량용도피해자 = pd.get_dummies(walker_60_suwon['차량용도피해자'], prefix='차량용도피해자')\n",
    "dummy_차량용도피해자_대분류 = pd.get_dummies(walker_60_suwon['차량용도피해자_대분류'], prefix='차량용도피해자_대분류')\n",
    "dummy_피해자성별 = pd.get_dummies(walker_60_suwon['피해자성별'], prefix='피해자성별')\n",
    "dummy_행동유형가해자 = pd.get_dummies(walker_60_suwon['행동유형가해자'], prefix='행동유형가해자')\n",
    "dummy_행동유형피해자 = pd.get_dummies(walker_60_suwon['행동유형피해자'], prefix='행동유형피해자')\n",
    "dummy_행동유형피해자_대분류 = pd.get_dummies(walker_60_suwon['행동유형피해자_대분류'], prefix='행동유형피해자_대분류')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "continues_cols = ['연령가해자','연령피해자']\n",
    "walker_60_continues = walker_60_suwon[continues_cols]\n",
    "\n",
    "walker_60_f = pd.concat([dummy_가해자성별, dummy_교차로형태, dummy_기상상태, dummy_노면상태, dummy_노면상태_대분류, dummy_노인보호구역, \n",
    "                        dummy_당사자종별가해자, dummy_당사자종별피해자, dummy_도로선형, dummy_도로선형_대분류, dummy_도로선형_중분류, \n",
    "                        dummy_도로종류, dummy_도로형태, dummy_법규위반가해자, dummy_보호장구가해자_대분류, \n",
    "                        dummy_보호장구피해자_대분류, dummy_사고유형, dummy_사고유형_대분류, dummy_어린이보호구역, dummy_요일, \n",
    "                        dummy_주야,dummy_차량용도가해자, dummy_차량용도가해자_대분류, dummy_차량용도피해자, dummy_차량용도피해자_대분류,\n",
    "                        dummy_피해자성별, dummy_행동유형가해자, dummy_행동유형피해자, dummy_행동유형피해자_대분류,walker_60_continues, \n",
    "                        walker_60_suwon['도로심각도지수basic']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "xval = walker_60_f[walker_60_f.columns.difference(['도로심각도지수basic'])]\n",
    "yval = walker_60_f['도로심각도지수basic']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(xval, yval, train_size=0.7, random_state=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "x_train['연령피해자'] = (x_train['연령피해자'] - x_train['연령피해자'].min(axis=0)) / (x_train['연령피해자'].max(axis=0) - x_train['연령피해자'].min(axis=0))\n",
    "x_train['연령가해자'] = (x_train['연령가해자'] - x_train['연령가해자'].min(axis=0)) / (x_train['연령가해자'].max(axis=0) - x_train['연령가해자'].min(axis=0))\n",
    "\n",
    "x_test['연령피해자'] = (x_test['연령피해자'] - x_test['연령피해자'].min(axis=0)) / (x_test['연령피해자'].max(axis=0) - x_test['연령피해자'].min(axis=0))\n",
    "x_test['연령가해자'] = (x_test['연령가해자'] - x_test['연령가해자'].min(axis=0)) / (x_test['연령가해자'].max(axis=0) - x_test['연령가해자'].min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reset_index()\n",
    "x_test = x_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['index'],axis=1)\n",
    "x_test = x_test.drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (1017, 178) (1017,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (1072, 178) (1072,)\n",
      "SMOTE 적용 후 레이블 값 분포: \n",
      " 1.0    536\n",
      "0.0    536\n",
      "Name: 도로심각도지수basic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=97)\n",
    "x_train_over,y_train_over = smote.fit_sample(x_train,y_train)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', x_train_over.shape, y_train_over.shape)\n",
    "print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        412  124\n",
      "1.0         98  438\n",
      "\n",
      "XGBoost for Ensemble - Train accuracy 0.793\n",
      "\n",
      "XGBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.77      0.79       536\n",
      "         1.0       0.78      0.82      0.80       536\n",
      "\n",
      "    accuracy                           0.79      1072\n",
      "   macro avg       0.79      0.79      0.79      1072\n",
      "weighted avg       0.79      0.79      0.79      1072\n",
      "\n",
      "\n",
      "XGBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        111   64\n",
      "1.0         98  164\n",
      "\n",
      "XGBoost for Ensemble - Test accuracy 0.629\n",
      "\n",
      "XGBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.63      0.58       175\n",
      "         1.0       0.72      0.63      0.67       262\n",
      "\n",
      "    accuracy                           0.63       437\n",
      "   macro avg       0.63      0.63      0.62       437\n",
      "weighted avg       0.64      0.63      0.63       437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#분류기1 - XG 부스트\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "clf1_xgb_fit = xgb.XGBClassifier(max_depth=2, n_estimators=5000, learning_rate=0.01)\n",
    "clf1_xgb_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "print(\"\\nXGBoost for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf1_xgb_fit.predict(x_train_over), rownames = [\"Actuall\"], colnames=['Predicted']))\n",
    "print(\"\\nXGBoost for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf1_xgb_fit.predict(x_train_over)),3))\n",
    "print(\"\\nXGBoost for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf1_xgb_fit.predict(x_train_over)))\n",
    "\n",
    "print(\"\\nXGBoost for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf1_xgb_fit.predict(x_test), rownames=[\"Actual\"], colnames=[\"Predicted\"]))\n",
    "print(\"\\nXGBoost for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf1_xgb_fit.predict(x_test)),3))\n",
    "print(\"\\nXGBoost for Ensemble - Test Classification Report\\n\", classification_report(y_test, clf1_xgb_fit.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        427  109\n",
      "1.0        276  260\n",
      "\n",
      "Decision Tree for Ensemble - Train accuracy 0.641\n",
      "\n",
      "Decision Tree for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.80      0.69       536\n",
      "         1.0       0.70      0.49      0.57       536\n",
      "\n",
      "    accuracy                           0.64      1072\n",
      "   macro avg       0.66      0.64      0.63      1072\n",
      "weighted avg       0.66      0.64      0.63      1072\n",
      "\n",
      "\n",
      "Decision Tree for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        115   60\n",
      "1.0        157  105\n",
      "\n",
      "Decision Tree for Ensemble - Test accuracy 0.503\n",
      "\n",
      "Decision Tree for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.66      0.51       175\n",
      "         1.0       0.64      0.40      0.49       262\n",
      "\n",
      "    accuracy                           0.50       437\n",
      "   macro avg       0.53      0.53      0.50       437\n",
      "weighted avg       0.55      0.50      0.50       437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#분류기2 - 의사결정나무\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf2_dt_fit = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "clf2_dt_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "print(\"\\nDecision Tree for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf2_dt_fit.predict(x_train_over), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "print(\"\\nDecision Tree for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf2_dt_fit.predict(x_train_over)),3))\n",
    "print(\"\\nDecision Tree for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf2_dt_fit.predict(x_train_over)))\n",
    "\n",
    "print(\"\\nDecision Tree for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf2_dt_fit.predict(x_test), rownames=[\"Actual\"], colnames=[\"Predicted\"]))\n",
    "print(\"\\nDecision Tree for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf2_dt_fit.predict(x_test)),3))\n",
    "print(\"\\nDecision Tree for Ensemble - Test Classification Report\\n\", classification_report(y_test, clf2_dt_fit.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        372  164\n",
      "1.0        133  403\n",
      "\n",
      "Random Forest for Ensemble - Train accuracy 0.723\n",
      "\n",
      "Random Forest for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.69      0.71       536\n",
      "         1.0       0.71      0.75      0.73       536\n",
      "\n",
      "    accuracy                           0.72      1072\n",
      "   macro avg       0.72      0.72      0.72      1072\n",
      "weighted avg       0.72      0.72      0.72      1072\n",
      "\n",
      "\n",
      "Random Forest for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        112   63\n",
      "1.0        106  156\n",
      "\n",
      "Random Forest for Ensemble - Test accuracy 0.613\n",
      "\n",
      "Random Forest for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.64      0.57       175\n",
      "         1.0       0.71      0.60      0.65       262\n",
      "\n",
      "    accuracy                           0.61       437\n",
      "   macro avg       0.61      0.62      0.61       437\n",
      "weighted avg       0.63      0.61      0.62       437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#분류기3 - 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf3_rf_fit = RandomForestClassifier(n_estimators=10000, criterion='gini', max_depth=6, min_samples_split=2, min_samples_leaf=1)\n",
    "clf3_rf_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "print(\"\\nRandom Forest for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf3_rf_fit.predict(x_train_over), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "print(\"\\nRandom Forest for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf3_rf_fit.predict(x_train_over)),3))\n",
    "print(\"\\nRandom Forest for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf3_rf_fit.predict(x_train_over)))\n",
    "\n",
    "print(\"\\nRandom Forest for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf3_rf_fit.predict(x_test), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "print(\"\\nRandom Forest for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf3_rf_fit.predict(x_test)),3))\n",
    "print(\"\\nRandom Forest for Ensemble - Test Classification Report\\n\", classification_report(y_test, clf3_rf_fit.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        344  192\n",
      "1.0        166  370\n",
      "\n",
      "AdaBoost for Ensemble - Train accuracy 0.666\n",
      "\n",
      "AdaBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.64      0.66       536\n",
      "         1.0       0.66      0.69      0.67       536\n",
      "\n",
      "    accuracy                           0.67      1072\n",
      "   macro avg       0.67      0.67      0.67      1072\n",
      "weighted avg       0.67      0.67      0.67      1072\n",
      "\n",
      "\n",
      "AdaBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0         98   77\n",
      "1.0         90  172\n",
      "\n",
      "AdaBoost for Ensemble - Test accuracy 0.618\n",
      "\n",
      "AdaBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.56      0.54       175\n",
      "         1.0       0.69      0.66      0.67       262\n",
      "\n",
      "    accuracy                           0.62       437\n",
      "   macro avg       0.61      0.61      0.61       437\n",
      "weighted avg       0.62      0.62      0.62       437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#분류기4 - 에이다 부스트\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf4_dtree = DecisionTreeClassifier(criterion='gini', max_depth=1)\n",
    "clf4_adabst_fit = AdaBoostClassifier(base_estimator=clf4_dtree, n_estimators=5000, learning_rate=0.01, random_state=97)\n",
    "clf4_adabst_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "print(\"\\nAdaBoost for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf4_adabst_fit.predict(x_train_over), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "print(\"\\nAdaBoost for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf4_adabst_fit.predict(x_train_over)),3))\n",
    "print(\"\\nAdaBoost for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf4_adabst_fit.predict(x_train_over)))\n",
    "\n",
    "print(\"\\nAdaBoost for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf4_adabst_fit.predict(x_test), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "print(\"\\nAdaBoost for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf4_adabst_fit.predict(x_test)),3))\n",
    "print(\"\\nAdaBoost for Ensemble - Test Classification Report\\n\", classification_report(y_test, clf4_adabst_fit.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        340  196\n",
      "1.0        139  397\n",
      "\n",
      "Logistic Regression for Ensemble - Train accuracy 0.688\n",
      "\n",
      "Logistic Regression for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.63      0.67       536\n",
      "         1.0       0.67      0.74      0.70       536\n",
      "\n",
      "    accuracy                           0.69      1072\n",
      "   macro avg       0.69      0.69      0.69      1072\n",
      "weighted avg       0.69      0.69      0.69      1072\n",
      "\n",
      "\n",
      "Logistic Regression for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0         95   80\n",
      "1.0         90  172\n",
      "\n",
      "Logistic Regression for Ensemble - Test accuracy 0.611\n",
      "\n",
      "Logistic Regression for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.54      0.53       175\n",
      "         1.0       0.68      0.66      0.67       262\n",
      "\n",
      "    accuracy                           0.61       437\n",
      "   macro avg       0.60      0.60      0.60       437\n",
      "weighted avg       0.61      0.61      0.61       437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#분류기5 - 로지스틱회귀\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf5_logreg_fit = LogisticRegression(fit_intercept = True)\n",
    "clf5_logreg_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "print(\"\\nLogistic Regression for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf5_logreg_fit.predict(x_train_over), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "print(\"\\nLogistic Regression for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf5_logreg_fit.predict(x_train_over)),3))\n",
    "print(\"\\nLogistic Regression for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf5_logreg_fit.predict(x_train_over)))\n",
    "\n",
    "print(\"\\nLogistic Regression for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf5_logreg_fit.predict(x_test), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "print(\"\\nLogistic Regression for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf5_logreg_fit.predict(x_test)),3))\n",
    "print(\"\\nLogistic Regression for Ensemble - Test Classification Report\\n\", classification_report(y_test,clf5_logreg_fit.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#메타 분류기\n",
    "\n",
    "ensemble = pd.DataFrame()\n",
    "\n",
    "ensemble[\"xgb_output_one\"] = pd.DataFrame(clf1_xgb_fit.predict_proba(x_train_over))[1]\n",
    "ensemble[\"dtr_output_one\"] = pd.DataFrame(clf2_dt_fit.predict_proba(x_train_over))[1]\n",
    "ensemble[\"rf_output_one\"] = pd.DataFrame(clf3_rf_fit.predict_proba(x_train_over))[1]\n",
    "ensemble[\"adb_output_one\"] = pd.DataFrame(clf4_adabst_fit.predict_proba(x_train_over))[1]\n",
    "ensemble[\"log_output_one\"] = pd.DataFrame(clf5_logreg_fit.predict_proba(x_train_over))[1]\n",
    "\n",
    "ensemble = pd.concat([ensemble, pd.DataFrame(y_train_over).reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-efficients for XGB, DT, RF, AB, LR are: [[ 7.44775164  0.79671871 -0.45988308 -6.40246378 -1.29531125]]\n",
      "\n",
      "\n",
      "Ensemble of Models - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        113   62\n",
      "1.0         97  165\n",
      "\n",
      "Ensemble of Models - Test accuracy 0.636\n",
      "\n",
      "Ensemble of Models - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.65      0.59       175\n",
      "         1.0       0.73      0.63      0.67       262\n",
      "\n",
      "    accuracy                           0.64       437\n",
      "   macro avg       0.63      0.64      0.63       437\n",
      "weighted avg       0.65      0.64      0.64       437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_logit_fit = LogisticRegression(fit_intercept=False)\n",
    "meta_logit_fit.fit(ensemble[['xgb_output_one',\"dtr_output_one\",\"rf_output_one\", \"adb_output_one\", \"log_output_one\"]], ensemble['도로심각도지수basic'])\n",
    "\n",
    "coefs =  meta_logit_fit.coef_\n",
    "print (\"Co-efficients for XGB, DT, RF, AB, LR are:\",coefs)\n",
    "\n",
    "ensemble_test = pd.DataFrame()\n",
    "ensemble_test['xgb_output_one'] = pd.DataFrame(clf1_xgb_fit.predict_proba(x_test))[1]\n",
    "ensemble_test[\"dtr_output_one\"] = pd.DataFrame(clf2_dt_fit.predict_proba(x_test))[1]\n",
    "ensemble_test[\"rf_output_one\"] = pd.DataFrame(clf3_rf_fit.predict_proba(x_test))[1]\n",
    "ensemble_test[\"adb_output_one\"] = pd.DataFrame(clf4_adabst_fit.predict_proba(x_test))[1]\n",
    "ensemble_test[\"log_output_one\"] = pd.DataFrame(clf5_logreg_fit.predict_proba(x_test))[1]\n",
    "\n",
    "ensemble_test[\"all_one\"] = meta_logit_fit.predict(ensemble_test[['xgb_output_one','dtr_output_one','rf_output_one','adb_output_one', \"log_output_one\"]])\n",
    "\n",
    "ensemble_test = pd.concat([ensemble_test,pd.DataFrame(y_test).reset_index(drop = True )],axis=1)\n",
    "\n",
    "print (\"\\n\\nEnsemble of Models - Test Confusion Matrix\\n\\n\",pd.crosstab(ensemble_test['도로심각도지수basic'],ensemble_test['all_one'],rownames = [\"Actuall\"],colnames = [\"Predicted\"]))      \n",
    "print (\"\\nEnsemble of Models - Test accuracy\",round(accuracy_score(ensemble_test['도로심각도지수basic'],ensemble_test['all_one']),3))\n",
    "print (\"\\nEnsemble of Models - Test Classification Report\\n\",classification_report(ensemble_test['도로심각도지수basic'],ensemble_test['all_one']))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
