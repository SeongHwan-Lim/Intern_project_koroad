{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "walker_60_suwon = pd.read_csv(\"D:\\\\jupyter_proj\\\\walker_60_suwon.csv\")\n",
    "    \n",
    "    \n",
    "for i in range(len(walker_60_suwon)):\n",
    "    if walker_60_suwon['도로심각도지수basic'][i] <= 0.1168:\n",
    "        walker_60_suwon['도로심각도지수basic'][i] = 0\n",
    "    else:\n",
    "        walker_60_suwon['도로심각도지수basic'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_가해자성별 = pd.get_dummies(walker_60_suwon['가해자성별'], prefix='가해자성별')\n",
    "dummy_교차로형태 = pd.get_dummies(walker_60_suwon['교차로형태'], prefix='교차로형태')\n",
    "dummy_기상상태 = pd.get_dummies(walker_60_suwon['기상상태'], prefix='기상상태')\n",
    "dummy_노면상태 = pd.get_dummies(walker_60_suwon['노면상태'], prefix='노면상태')\n",
    "dummy_노면상태_대분류 = pd.get_dummies(walker_60_suwon['노면상태_대분류'], prefix='노면상태_대분류')\n",
    "dummy_노인보호구역 = pd.get_dummies(walker_60_suwon['노인보호구역'], prefix='노인보호구역')\n",
    "dummy_당사자종별가해자 = pd.get_dummies(walker_60_suwon['당사자종별가해자'], prefix='당사자종별가해자')\n",
    "dummy_당사자종별피해자 = pd.get_dummies(walker_60_suwon['당사자종별피해자'], prefix='당사자종별피해자')\n",
    "dummy_도로선형 = pd.get_dummies(walker_60_suwon['도로선형'], prefix='도로선형')\n",
    "dummy_도로선형_대분류 = pd.get_dummies(walker_60_suwon['도로선형_대분류'], prefix='도로선형_대분류')\n",
    "dummy_도로선형_중분류 = pd.get_dummies(walker_60_suwon['도로선형_중분류'], prefix='도로선형_중분류')\n",
    "dummy_도로종류 = pd.get_dummies(walker_60_suwon['도로종류'], prefix='도로종류')\n",
    "dummy_도로형태 = pd.get_dummies(walker_60_suwon['도로형태'], prefix='도로형태')\n",
    "dummy_법규위반가해자 = pd.get_dummies(walker_60_suwon['법규위반가해자'], prefix='법규위반가해자')\n",
    "dummy_보호장구가해자_대분류 = pd.get_dummies(walker_60_suwon['보호장구가해자_대분류'], prefix='보호장구가해자_대분류')\n",
    "dummy_보호장구피해자_대분류 = pd.get_dummies(walker_60_suwon['보호장구피해자_대분류'], prefix='보호장구피해자_대분류')\n",
    "dummy_사고유형 = pd.get_dummies(walker_60_suwon['사고유형'], prefix='사고유형')\n",
    "dummy_사고유형_대분류 = pd.get_dummies(walker_60_suwon['사고유형_대분류'], prefix='사고유형_대분류')\n",
    "dummy_어린이보호구역 = pd.get_dummies(walker_60_suwon['어린이보호구역'], prefix='어린이보호구역')\n",
    "dummy_요일 = pd.get_dummies(walker_60_suwon['요일'], prefix='요일')\n",
    "dummy_주야 = pd.get_dummies(walker_60_suwon['주야'], prefix='주야')\n",
    "dummy_차량용도가해자 = pd.get_dummies(walker_60_suwon['차량용도가해자'], prefix='차량용도가해자')\n",
    "dummy_차량용도가해자_대분류 = pd.get_dummies(walker_60_suwon['차량용도가해자_대분류'], prefix='차량용도가해자_대분류')\n",
    "dummy_차량용도피해자 = pd.get_dummies(walker_60_suwon['차량용도피해자'], prefix='차량용도피해자')\n",
    "dummy_차량용도피해자_대분류 = pd.get_dummies(walker_60_suwon['차량용도피해자_대분류'], prefix='차량용도피해자_대분류')\n",
    "dummy_피해자성별 = pd.get_dummies(walker_60_suwon['피해자성별'], prefix='피해자성별')\n",
    "dummy_행동유형가해자 = pd.get_dummies(walker_60_suwon['행동유형가해자'], prefix='행동유형가해자')\n",
    "dummy_행동유형피해자 = pd.get_dummies(walker_60_suwon['행동유형피해자'], prefix='행동유형피해자')\n",
    "dummy_행동유형피해자_대분류 = pd.get_dummies(walker_60_suwon['행동유형피해자_대분류'], prefix='행동유형피해자_대분류')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "continues_cols = ['연령가해자','연령피해자']\n",
    "walker_60_continues = walker_60_suwon[continues_cols]\n",
    "\n",
    "walker_60_f = pd.concat([dummy_가해자성별, dummy_교차로형태, dummy_기상상태, dummy_노면상태, dummy_노면상태_대분류, dummy_노인보호구역, \n",
    "                        dummy_당사자종별가해자, dummy_당사자종별피해자, dummy_도로선형, dummy_도로선형_대분류, dummy_도로선형_중분류, \n",
    "                        dummy_도로종류, dummy_도로형태, dummy_법규위반가해자, dummy_보호장구가해자_대분류, \n",
    "                        dummy_보호장구피해자_대분류, dummy_사고유형, dummy_사고유형_대분류, dummy_어린이보호구역, dummy_요일, \n",
    "                        dummy_주야,dummy_차량용도가해자, dummy_차량용도가해자_대분류, dummy_차량용도피해자, dummy_차량용도피해자_대분류,\n",
    "                        dummy_피해자성별, dummy_행동유형가해자, dummy_행동유형피해자, dummy_행동유형피해자_대분류,walker_60_continues, \n",
    "                        walker_60_suwon['도로심각도지수basic']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmscale(x_train, x_test):\n",
    "\n",
    "    x_train['연령피해자'] = (x_train['연령피해자'] - x_train['연령피해자'].min(axis=0)) / (x_train['연령피해자'].max(axis=0) - x_train['연령피해자'].min(axis=0))\n",
    "    x_train['연령가해자'] = (x_train['연령가해자'] - x_train['연령가해자'].min(axis=0)) / (x_train['연령가해자'].max(axis=0) - x_train['연령가해자'].min(axis=0))\n",
    "\n",
    "    x_test['연령피해자'] = (x_test['연령피해자'] - x_test['연령피해자'].min(axis=0)) / (x_test['연령피해자'].max(axis=0) - x_test['연령피해자'].min(axis=0))\n",
    "    x_test['연령가해자'] = (x_test['연령가해자'] - x_test['연령가해자'].min(axis=0)) / (x_test['연령가해자'].max(axis=0) - x_test['연령가해자'].min(axis=0))\n",
    "    \n",
    "    x_train_mm = x_train\n",
    "    x_test_mm = x_test\n",
    "\n",
    "    \n",
    "    return x_train_mm, x_test_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smt(x_train, y_train):\n",
    "    smote = SMOTE(random_state=97)\n",
    "    \n",
    "    x_train_over,y_train_over = smote.fit_sample(x_train,list(y_train))\n",
    "    y_train_over = np.array(y_train_over)\n",
    "    print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, (np.array(y_train)).shape)\n",
    "    print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', x_train_over.shape, y_train_over.shape)\n",
    "    print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())\n",
    "    \n",
    "    return x_train_over,y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#분류기1 - XG 부스트\n",
    "\n",
    "def xgb_f(x_train_over, y_train_over, x_test, y_test):\n",
    "    clf1_xgb_fit = xgb.XGBClassifier(max_depth=2, n_estimators=5000, learning_rate=0.01)\n",
    "    clf1_xgb_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "    print(\"\\nXGBoost for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf1_xgb_fit.predict(x_train_over), rownames = [\"Actuall\"], colnames=['Predicted']))\n",
    "    print(\"\\nXGBoost for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf1_xgb_fit.predict(x_train_over)),3))\n",
    "    print(\"\\nXGBoost for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf1_xgb_fit.predict(x_train_over)))\n",
    "\n",
    "    print(\"\\nXGBoost for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf1_xgb_fit.predict(x_test), rownames=[\"Actual\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nXGBoost for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf1_xgb_fit.predict(x_test)),3))\n",
    "    print(\"\\nXGBoost for Ensemble - Test Classification Report\\n\", classification_report(y_test, clf1_xgb_fit.predict(x_test)))\n",
    "    \n",
    "    return clf1_xgb_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분류기2 - 의사결정나무\n",
    "\n",
    "def dt_f(x_train_over, y_train_over, x_test, y_test):\n",
    "    clf2_dt_fit = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "    clf2_dt_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "    print(\"\\nDecision Tree for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf2_dt_fit.predict(x_train_over), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nDecision Tree for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf2_dt_fit.predict(x_train_over)),3))\n",
    "    print(\"\\nDecision Tree for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf2_dt_fit.predict(x_train_over)))\n",
    "\n",
    "    print(\"\\nDecision Tree for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf2_dt_fit.predict(x_test), rownames=[\"Actual\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nDecision Tree for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf2_dt_fit.predict(x_test)),3))\n",
    "    print(\"\\nDecision Tree for Ensemble - Test Classification Report\\n\", classification_report(y_test, clf2_dt_fit.predict(x_test)))\n",
    "    \n",
    "    return clf2_dt_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분류기3 - 랜덤포레스트\n",
    "\n",
    "def rf_f(x_train_over, y_train_over, x_test, y_test):\n",
    "    clf3_rf_fit = RandomForestClassifier(n_estimators=10000, criterion='gini', max_depth=6, min_samples_split=2, min_samples_leaf=1)\n",
    "    clf3_rf_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "    print(\"\\nRandom Forest for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf3_rf_fit.predict(x_train_over), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nRandom Forest for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf3_rf_fit.predict(x_train_over)),3))\n",
    "    print(\"\\nRandom Forest for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf3_rf_fit.predict(x_train_over)))\n",
    "\n",
    "    print(\"\\nRandom Forest for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf3_rf_fit.predict(x_test), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nRandom Forest for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf3_rf_fit.predict(x_test)),3))\n",
    "    print(\"\\nRandom Forest for Ensemble - Test Classification Report\\n\", classification_report(y_test, clf3_rf_fit.predict(x_test)))\n",
    "    \n",
    "    return clf3_rf_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#분류기4 - 에이다 부스트\n",
    "\n",
    "def ada_f(x_train_over, y_train_over, x_test, y_test):\n",
    "    clf4_dtree = DecisionTreeClassifier(criterion='gini', max_depth=1)\n",
    "    clf4_adabst_fit = AdaBoostClassifier(base_estimator=clf4_dtree, n_estimators=5000, learning_rate=0.01, random_state=97)\n",
    "    clf4_adabst_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "    print(\"\\nAdaBoost for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf4_adabst_fit.predict(x_train_over), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nAdaBoost for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf4_adabst_fit.predict(x_train_over)),3))\n",
    "    print(\"\\nAdaBoost for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf4_adabst_fit.predict(x_train_over)))\n",
    "\n",
    "    print(\"\\nAdaBoost for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf4_adabst_fit.predict(x_test), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nAdaBoost for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf4_adabst_fit.predict(x_test)),3))\n",
    "    print(\"\\nAdaBoost for Ensemble - Test Classification Report\\n\", classification_report(y_test, clf4_adabst_fit.predict(x_test)))\n",
    "    \n",
    "    return clf4_adabst_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분류기5 - 로지스틱회귀\n",
    "\n",
    "def lr_f(x_train_over, y_train_over, x_test, y_test):\n",
    "    clf5_logreg_fit = LogisticRegression(fit_intercept = True)\n",
    "    clf5_logreg_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "    print(\"\\nLogistic Regression for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf5_logreg_fit.predict(x_train_over), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nLogistic Regression for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf5_logreg_fit.predict(x_train_over)),3))\n",
    "    print(\"\\nLogistic Regression for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf5_logreg_fit.predict(x_train_over)))\n",
    "\n",
    "    print(\"\\nLogistic Regression for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf5_logreg_fit.predict(x_test), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nLogistic Regression for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf5_logreg_fit.predict(x_test)),3))\n",
    "    print(\"\\nLogistic Regression for Ensemble - Test Classification Report\\n\", classification_report(y_test,clf5_logreg_fit.predict(x_test)))\n",
    "\n",
    "    return clf5_logreg_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#메타 분류기\n",
    "\n",
    "def meta_f1(clf1_xgb_fit, clf2_dt_fit, clf3_rf_fit, clf4_adabst_fit, clf5_logreg_fit, x_train_over, y_train_over):\n",
    "    ensemble = pd.DataFrame()\n",
    "\n",
    "    ensemble[\"xgb_output_one\"] = pd.DataFrame(clf1_xgb_fit.predict_proba(x_train_over))[1]\n",
    "    ensemble[\"dtr_output_one\"] = pd.DataFrame(clf2_dt_fit.predict_proba(x_train_over))[1]\n",
    "    ensemble[\"rf_output_one\"] = pd.DataFrame(clf3_rf_fit.predict_proba(x_train_over))[1]\n",
    "    ensemble[\"adb_output_one\"] = pd.DataFrame(clf4_adabst_fit.predict_proba(x_train_over))[1]\n",
    "    ensemble[\"log_output_one\"] = pd.DataFrame(clf5_logreg_fit.predict_proba(x_train_over))[1]\n",
    "    \n",
    "    y_train_over_ens = pd.DataFrame(y_train_over).reset_index(drop=True)\n",
    "    y_train_over_ens.columns = ['도로심각도지수basic']\n",
    "\n",
    "    ensemble = pd.concat([ensemble, y_train_over_ens], axis=1)\n",
    "\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_f2(ensemble, clf1_xgb_fit, clf2_dt_fit, clf3_rf_fit, clf4_adabst_fit, clf5_logreg_fit, x_test, y_test):\n",
    "    meta_logit_fit = LogisticRegression(fit_intercept=False)\n",
    "    meta_logit_fit.fit(ensemble[['xgb_output_one',\"dtr_output_one\",\"rf_output_one\", \"adb_output_one\", \"log_output_one\"]], ensemble['도로심각도지수basic'])\n",
    "\n",
    "    coefs =  meta_logit_fit.coef_\n",
    "    print (\"Co-efficients for XGB, DT, RF, AB, LR are:\",coefs)\n",
    "\n",
    "    ensemble_test = pd.DataFrame()\n",
    "    ensemble_test['xgb_output_one'] = pd.DataFrame(clf1_xgb_fit.predict_proba(x_test))[1]\n",
    "    ensemble_test[\"dtr_output_one\"] = pd.DataFrame(clf2_dt_fit.predict_proba(x_test))[1]\n",
    "    ensemble_test[\"rf_output_one\"] = pd.DataFrame(clf3_rf_fit.predict_proba(x_test))[1]\n",
    "    ensemble_test[\"adb_output_one\"] = pd.DataFrame(clf4_adabst_fit.predict_proba(x_test))[1]\n",
    "    ensemble_test[\"log_output_one\"] = pd.DataFrame(clf5_logreg_fit.predict_proba(x_test))[1]\n",
    "\n",
    "    ensemble_test[\"all_one\"] = meta_logit_fit.predict(ensemble_test[['xgb_output_one','dtr_output_one','rf_output_one','adb_output_one', \"log_output_one\"]])\n",
    "\n",
    "    ensemble_test = pd.concat([ensemble_test,pd.DataFrame(y_test).reset_index(drop = True )],axis=1)\n",
    "\n",
    "    print (\"\\n\\nEnsemble of Models - Test Confusion Matrix\\n\\n\",pd.crosstab(ensemble_test['도로심각도지수basic'],ensemble_test['all_one'],rownames = [\"Actuall\"],colnames = [\"Predicted\"]))      \n",
    "    print (\"\\nEnsemble of Models - Test accuracy\",round(accuracy_score(ensemble_test['도로심각도지수basic'],ensemble_test['all_one']),3))\n",
    "    print (\"\\nEnsemble of Models - Test Classification Report\\n\",classification_report(ensemble_test['도로심각도지수basic'],ensemble_test['all_one']))\n",
    "\n",
    "    meta_acc = round(accuracy_score(ensemble_test['도로심각도지수basic'],ensemble_test['all_one']),3)\n",
    "    \n",
    "    return meta_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------교차검증 번호: 1------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (1163, 178) (1163,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2204, 178) (2204,)\n",
      "SMOTE 적용 후 레이블 값 분포: \n",
      " 1.0    1102\n",
      "0.0    1102\n",
      "dtype: int64\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1096     6\n",
      "1.0          36  1066\n",
      "\n",
      "XGBoost for Ensemble - Train accuracy 0.981\n",
      "\n",
      "XGBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      1102\n",
      "         1.0       0.99      0.97      0.98      1102\n",
      "\n",
      "    accuracy                           0.98      2204\n",
      "   macro avg       0.98      0.98      0.98      2204\n",
      "weighted avg       0.98      0.98      0.98      2204\n",
      "\n",
      "\n",
      "XGBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        271    4\n",
      "1.0         16    0\n",
      "\n",
      "XGBoost for Ensemble - Test accuracy 0.931\n",
      "\n",
      "XGBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96       275\n",
      "         1.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.93       291\n",
      "   macro avg       0.47      0.49      0.48       291\n",
      "weighted avg       0.89      0.93      0.91       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Decision Tree for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted  0.0   1.0\n",
      "Actuall             \n",
      "0.0        800   302\n",
      "1.0         91  1011\n",
      "\n",
      "Decision Tree for Ensemble - Train accuracy 0.822\n",
      "\n",
      "Decision Tree for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.73      0.80      1102\n",
      "         1.0       0.77      0.92      0.84      1102\n",
      "\n",
      "    accuracy                           0.82      2204\n",
      "   macro avg       0.83      0.82      0.82      2204\n",
      "weighted avg       0.83      0.82      0.82      2204\n",
      "\n",
      "\n",
      "Decision Tree for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        148  127\n",
      "1.0         12    4\n",
      "\n",
      "Decision Tree for Ensemble - Test accuracy 0.522\n",
      "\n",
      "Decision Tree for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.54      0.68       275\n",
      "         1.0       0.03      0.25      0.05        16\n",
      "\n",
      "    accuracy                           0.52       291\n",
      "   macro avg       0.48      0.39      0.37       291\n",
      "weighted avg       0.88      0.52      0.65       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Random Forest for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1022    80\n",
      "1.0          20  1082\n",
      "\n",
      "Random Forest for Ensemble - Train accuracy 0.955\n",
      "\n",
      "Random Forest for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95      1102\n",
      "         1.0       0.93      0.98      0.96      1102\n",
      "\n",
      "    accuracy                           0.95      2204\n",
      "   macro avg       0.96      0.95      0.95      2204\n",
      "weighted avg       0.96      0.95      0.95      2204\n",
      "\n",
      "\n",
      "Random Forest for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        256   19\n",
      "1.0         15    1\n",
      "\n",
      "Random Forest for Ensemble - Test accuracy 0.883\n",
      "\n",
      "Random Forest for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.94       275\n",
      "         1.0       0.05      0.06      0.06        16\n",
      "\n",
      "    accuracy                           0.88       291\n",
      "   macro avg       0.50      0.50      0.50       291\n",
      "weighted avg       0.90      0.88      0.89       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "AdaBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1072    30\n",
      "1.0          55  1047\n",
      "\n",
      "AdaBoost for Ensemble - Train accuracy 0.961\n",
      "\n",
      "AdaBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96      1102\n",
      "         1.0       0.97      0.95      0.96      1102\n",
      "\n",
      "    accuracy                           0.96      2204\n",
      "   macro avg       0.96      0.96      0.96      2204\n",
      "weighted avg       0.96      0.96      0.96      2204\n",
      "\n",
      "\n",
      "AdaBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        264   11\n",
      "1.0         14    2\n",
      "\n",
      "AdaBoost for Ensemble - Test accuracy 0.914\n",
      "\n",
      "AdaBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95       275\n",
      "         1.0       0.15      0.12      0.14        16\n",
      "\n",
      "    accuracy                           0.91       291\n",
      "   macro avg       0.55      0.54      0.55       291\n",
      "weighted avg       0.91      0.91      0.91       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression for Ensemble - Train Confusion Matrix\n",
      "\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1100     2\n",
      "1.0          58  1044\n",
      "\n",
      "Logistic Regression for Ensemble - Train accuracy 0.973\n",
      "\n",
      "Logistic Regression for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      1102\n",
      "         1.0       1.00      0.95      0.97      1102\n",
      "\n",
      "    accuracy                           0.97      2204\n",
      "   macro avg       0.97      0.97      0.97      2204\n",
      "weighted avg       0.97      0.97      0.97      2204\n",
      "\n",
      "\n",
      "Logistic Regression for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0\n",
      "Actuall       \n",
      "0.0        275\n",
      "1.0         16\n",
      "\n",
      "Logistic Regression for Ensemble - Test accuracy 0.945\n",
      "\n",
      "Logistic Regression for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97       275\n",
      "         1.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.95       291\n",
      "   macro avg       0.47      0.50      0.49       291\n",
      "weighted avg       0.89      0.95      0.92       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-efficients for XGB, DT, RF, AB, LR are: [[ 7.33282666  0.69460447 -1.09481131 -7.64567802  2.56818555]]\n",
      "\n",
      "\n",
      "Ensemble of Models - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        271    4\n",
      "1.0         16    0\n",
      "\n",
      "Ensemble of Models - Test accuracy 0.931\n",
      "\n",
      "Ensemble of Models - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96       275\n",
      "         1.0       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.93       291\n",
      "   macro avg       0.47      0.49      0.48       291\n",
      "weighted avg       0.89      0.93      0.91       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------교차검증 번호: 2------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (1163, 178) (1163,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2202, 178) (2202,)\n",
      "SMOTE 적용 후 레이블 값 분포: \n",
      " 1.0    1101\n",
      "0.0    1101\n",
      "dtype: int64\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1094     7\n",
      "1.0          34  1067\n",
      "\n",
      "XGBoost for Ensemble - Train accuracy 0.981\n",
      "\n",
      "XGBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      1101\n",
      "         1.0       0.99      0.97      0.98      1101\n",
      "\n",
      "    accuracy                           0.98      2202\n",
      "   macro avg       0.98      0.98      0.98      2202\n",
      "weighted avg       0.98      0.98      0.98      2202\n",
      "\n",
      "\n",
      "XGBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        273    3\n",
      "1.0         15    0\n",
      "\n",
      "XGBoost for Ensemble - Test accuracy 0.938\n",
      "\n",
      "XGBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97       276\n",
      "         1.0       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.94       291\n",
      "   macro avg       0.47      0.49      0.48       291\n",
      "weighted avg       0.90      0.94      0.92       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Decision Tree for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted  0.0   1.0\n",
      "Actuall             \n",
      "0.0        781   320\n",
      "1.0         76  1025\n",
      "\n",
      "Decision Tree for Ensemble - Train accuracy 0.82\n",
      "\n",
      "Decision Tree for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.71      0.80      1101\n",
      "         1.0       0.76      0.93      0.84      1101\n",
      "\n",
      "    accuracy                           0.82      2202\n",
      "   macro avg       0.84      0.82      0.82      2202\n",
      "weighted avg       0.84      0.82      0.82      2202\n",
      "\n",
      "\n",
      "Decision Tree for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        188   88\n",
      "1.0          7    8\n",
      "\n",
      "Decision Tree for Ensemble - Test accuracy 0.674\n",
      "\n",
      "Decision Tree for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.68      0.80       276\n",
      "         1.0       0.08      0.53      0.14        15\n",
      "\n",
      "    accuracy                           0.67       291\n",
      "   macro avg       0.52      0.61      0.47       291\n",
      "weighted avg       0.92      0.67      0.76       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Random Forest for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1034    67\n",
      "1.0          43  1058\n",
      "\n",
      "Random Forest for Ensemble - Train accuracy 0.95\n",
      "\n",
      "Random Forest for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95      1101\n",
      "         1.0       0.94      0.96      0.95      1101\n",
      "\n",
      "    accuracy                           0.95      2202\n",
      "   macro avg       0.95      0.95      0.95      2202\n",
      "weighted avg       0.95      0.95      0.95      2202\n",
      "\n",
      "\n",
      "Random Forest for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        249   27\n",
      "1.0         13    2\n",
      "\n",
      "Random Forest for Ensemble - Test accuracy 0.863\n",
      "\n",
      "Random Forest for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.90      0.93       276\n",
      "         1.0       0.07      0.13      0.09        15\n",
      "\n",
      "    accuracy                           0.86       291\n",
      "   macro avg       0.51      0.52      0.51       291\n",
      "weighted avg       0.90      0.86      0.88       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "AdaBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1057    44\n",
      "1.0          60  1041\n",
      "\n",
      "AdaBoost for Ensemble - Train accuracy 0.953\n",
      "\n",
      "AdaBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95      1101\n",
      "         1.0       0.96      0.95      0.95      1101\n",
      "\n",
      "    accuracy                           0.95      2202\n",
      "   macro avg       0.95      0.95      0.95      2202\n",
      "weighted avg       0.95      0.95      0.95      2202\n",
      "\n",
      "\n",
      "AdaBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        267    9\n",
      "1.0         15    0\n",
      "\n",
      "AdaBoost for Ensemble - Test accuracy 0.918\n",
      "\n",
      "AdaBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96       276\n",
      "         1.0       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.92       291\n",
      "   macro avg       0.47      0.48      0.48       291\n",
      "weighted avg       0.90      0.92      0.91       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1097     4\n",
      "1.0          52  1049\n",
      "\n",
      "Logistic Regression for Ensemble - Train accuracy 0.975\n",
      "\n",
      "Logistic Regression for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98      1101\n",
      "         1.0       1.00      0.95      0.97      1101\n",
      "\n",
      "    accuracy                           0.97      2202\n",
      "   macro avg       0.98      0.97      0.97      2202\n",
      "weighted avg       0.98      0.97      0.97      2202\n",
      "\n",
      "\n",
      "Logistic Regression for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        274    2\n",
      "1.0         15    0\n",
      "\n",
      "Logistic Regression for Ensemble - Test accuracy 0.942\n",
      "\n",
      "Logistic Regression for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97       276\n",
      "         1.0       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.94       291\n",
      "   macro avg       0.47      0.50      0.48       291\n",
      "weighted avg       0.90      0.94      0.92       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Co-efficients for XGB, DT, RF, AB, LR are: [[ 6.82149704  0.6241244  -1.43329235 -7.5239163   3.09523422]]\n",
      "\n",
      "\n",
      "Ensemble of Models - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        272    4\n",
      "1.0         15    0\n",
      "\n",
      "Ensemble of Models - Test accuracy 0.935\n",
      "\n",
      "Ensemble of Models - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97       276\n",
      "         1.0       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.93       291\n",
      "   macro avg       0.47      0.49      0.48       291\n",
      "weighted avg       0.90      0.93      0.92       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------교차검증 번호: 3------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (1163, 178) (1163,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2208, 178) (2208,)\n",
      "SMOTE 적용 후 레이블 값 분포: \n",
      " 1.0    1104\n",
      "0.0    1104\n",
      "dtype: int64\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1099     5\n",
      "1.0          33  1071\n",
      "\n",
      "XGBoost for Ensemble - Train accuracy 0.983\n",
      "\n",
      "XGBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      1104\n",
      "         1.0       1.00      0.97      0.98      1104\n",
      "\n",
      "    accuracy                           0.98      2208\n",
      "   macro avg       0.98      0.98      0.98      2208\n",
      "weighted avg       0.98      0.98      0.98      2208\n",
      "\n",
      "\n",
      "XGBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        268    5\n",
      "1.0         16    2\n",
      "\n",
      "XGBoost for Ensemble - Test accuracy 0.928\n",
      "\n",
      "XGBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96       273\n",
      "         1.0       0.29      0.11      0.16        18\n",
      "\n",
      "    accuracy                           0.93       291\n",
      "   macro avg       0.61      0.55      0.56       291\n",
      "weighted avg       0.90      0.93      0.91       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Decision Tree for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        929  175\n",
      "1.0        299  805\n",
      "\n",
      "Decision Tree for Ensemble - Train accuracy 0.785\n",
      "\n",
      "Decision Tree for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.84      0.80      1104\n",
      "         1.0       0.82      0.73      0.77      1104\n",
      "\n",
      "    accuracy                           0.79      2208\n",
      "   macro avg       0.79      0.79      0.78      2208\n",
      "weighted avg       0.79      0.79      0.78      2208\n",
      "\n",
      "\n",
      "Decision Tree for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        225   48\n",
      "1.0         11    7\n",
      "\n",
      "Decision Tree for Ensemble - Test accuracy 0.797\n",
      "\n",
      "Decision Tree for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.82      0.88       273\n",
      "         1.0       0.13      0.39      0.19        18\n",
      "\n",
      "    accuracy                           0.80       291\n",
      "   macro avg       0.54      0.61      0.54       291\n",
      "weighted avg       0.90      0.80      0.84       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Random Forest for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1008    96\n",
      "1.0          21  1083\n",
      "\n",
      "Random Forest for Ensemble - Train accuracy 0.947\n",
      "\n",
      "Random Forest for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.91      0.95      1104\n",
      "         1.0       0.92      0.98      0.95      1104\n",
      "\n",
      "    accuracy                           0.95      2208\n",
      "   macro avg       0.95      0.95      0.95      2208\n",
      "weighted avg       0.95      0.95      0.95      2208\n",
      "\n",
      "\n",
      "Random Forest for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        244   29\n",
      "1.0         14    4\n",
      "\n",
      "Random Forest for Ensemble - Test accuracy 0.852\n",
      "\n",
      "Random Forest for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.89      0.92       273\n",
      "         1.0       0.12      0.22      0.16        18\n",
      "\n",
      "    accuracy                           0.85       291\n",
      "   macro avg       0.53      0.56      0.54       291\n",
      "weighted avg       0.89      0.85      0.87       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "AdaBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1052    52\n",
      "1.0          52  1052\n",
      "\n",
      "AdaBoost for Ensemble - Train accuracy 0.953\n",
      "\n",
      "AdaBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95      1104\n",
      "         1.0       0.95      0.95      0.95      1104\n",
      "\n",
      "    accuracy                           0.95      2208\n",
      "   macro avg       0.95      0.95      0.95      2208\n",
      "weighted avg       0.95      0.95      0.95      2208\n",
      "\n",
      "\n",
      "AdaBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        262   11\n",
      "1.0         14    4\n",
      "\n",
      "AdaBoost for Ensemble - Test accuracy 0.914\n",
      "\n",
      "AdaBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95       273\n",
      "         1.0       0.27      0.22      0.24        18\n",
      "\n",
      "    accuracy                           0.91       291\n",
      "   macro avg       0.61      0.59      0.60       291\n",
      "weighted avg       0.91      0.91      0.91       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1104     0\n",
      "1.0          56  1048\n",
      "\n",
      "Logistic Regression for Ensemble - Train accuracy 0.975\n",
      "\n",
      "Logistic Regression for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98      1104\n",
      "         1.0       1.00      0.95      0.97      1104\n",
      "\n",
      "    accuracy                           0.97      2208\n",
      "   macro avg       0.98      0.97      0.97      2208\n",
      "weighted avg       0.98      0.97      0.97      2208\n",
      "\n",
      "\n",
      "Logistic Regression for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        271    2\n",
      "1.0         17    1\n",
      "\n",
      "Logistic Regression for Ensemble - Test accuracy 0.935\n",
      "\n",
      "Logistic Regression for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.97       273\n",
      "         1.0       0.33      0.06      0.10        18\n",
      "\n",
      "    accuracy                           0.93       291\n",
      "   macro avg       0.64      0.52      0.53       291\n",
      "weighted avg       0.90      0.93      0.91       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Co-efficients for XGB, DT, RF, AB, LR are: [[ 7.03419609  0.44060572 -1.36042885 -7.53925654  3.10287543]]\n",
      "\n",
      "\n",
      "Ensemble of Models - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        268    5\n",
      "1.0         15    3\n",
      "\n",
      "Ensemble of Models - Test accuracy 0.931\n",
      "\n",
      "Ensemble of Models - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.96       273\n",
      "         1.0       0.38      0.17      0.23        18\n",
      "\n",
      "    accuracy                           0.93       291\n",
      "   macro avg       0.66      0.57      0.60       291\n",
      "weighted avg       0.91      0.93      0.92       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------교차검증 번호: 4------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (1163, 178) (1163,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2206, 178) (2206,)\n",
      "SMOTE 적용 후 레이블 값 분포: \n",
      " 1.0    1103\n",
      "0.0    1103\n",
      "dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "XGBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1098     5\n",
      "1.0          38  1065\n",
      "\n",
      "XGBoost for Ensemble - Train accuracy 0.981\n",
      "\n",
      "XGBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      1103\n",
      "         1.0       1.00      0.97      0.98      1103\n",
      "\n",
      "    accuracy                           0.98      2206\n",
      "   macro avg       0.98      0.98      0.98      2206\n",
      "weighted avg       0.98      0.98      0.98      2206\n",
      "\n",
      "\n",
      "XGBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        270    4\n",
      "1.0         16    1\n",
      "\n",
      "XGBoost for Ensemble - Test accuracy 0.931\n",
      "\n",
      "XGBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96       274\n",
      "         1.0       0.20      0.06      0.09        17\n",
      "\n",
      "    accuracy                           0.93       291\n",
      "   macro avg       0.57      0.52      0.53       291\n",
      "weighted avg       0.90      0.93      0.91       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Decision Tree for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        893  210\n",
      "1.0        158  945\n",
      "\n",
      "Decision Tree for Ensemble - Train accuracy 0.833\n",
      "\n",
      "Decision Tree for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.81      0.83      1103\n",
      "         1.0       0.82      0.86      0.84      1103\n",
      "\n",
      "    accuracy                           0.83      2206\n",
      "   macro avg       0.83      0.83      0.83      2206\n",
      "weighted avg       0.83      0.83      0.83      2206\n",
      "\n",
      "\n",
      "Decision Tree for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        193   81\n",
      "1.0         12    5\n",
      "\n",
      "Decision Tree for Ensemble - Test accuracy 0.68\n",
      "\n",
      "Decision Tree for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.70      0.81       274\n",
      "         1.0       0.06      0.29      0.10        17\n",
      "\n",
      "    accuracy                           0.68       291\n",
      "   macro avg       0.50      0.50      0.45       291\n",
      "weighted avg       0.89      0.68      0.76       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Random Forest for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1034    69\n",
      "1.0          34  1069\n",
      "\n",
      "Random Forest for Ensemble - Train accuracy 0.953\n",
      "\n",
      "Random Forest for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95      1103\n",
      "         1.0       0.94      0.97      0.95      1103\n",
      "\n",
      "    accuracy                           0.95      2206\n",
      "   macro avg       0.95      0.95      0.95      2206\n",
      "weighted avg       0.95      0.95      0.95      2206\n",
      "\n",
      "\n",
      "Random Forest for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        248   26\n",
      "1.0         10    7\n",
      "\n",
      "Random Forest for Ensemble - Test accuracy 0.876\n",
      "\n",
      "Random Forest for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.93       274\n",
      "         1.0       0.21      0.41      0.28        17\n",
      "\n",
      "    accuracy                           0.88       291\n",
      "   macro avg       0.59      0.66      0.61       291\n",
      "weighted avg       0.92      0.88      0.89       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "AdaBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1058    45\n",
      "1.0          54  1049\n",
      "\n",
      "AdaBoost for Ensemble - Train accuracy 0.955\n",
      "\n",
      "AdaBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96      1103\n",
      "         1.0       0.96      0.95      0.95      1103\n",
      "\n",
      "    accuracy                           0.96      2206\n",
      "   macro avg       0.96      0.96      0.96      2206\n",
      "weighted avg       0.96      0.96      0.96      2206\n",
      "\n",
      "\n",
      "AdaBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        261   13\n",
      "1.0         15    2\n",
      "\n",
      "AdaBoost for Ensemble - Test accuracy 0.904\n",
      "\n",
      "AdaBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       274\n",
      "         1.0       0.13      0.12      0.12        17\n",
      "\n",
      "    accuracy                           0.90       291\n",
      "   macro avg       0.54      0.54      0.54       291\n",
      "weighted avg       0.90      0.90      0.90       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1101     2\n",
      "1.0          57  1046\n",
      "\n",
      "Logistic Regression for Ensemble - Train accuracy 0.973\n",
      "\n",
      "Logistic Regression for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      1103\n",
      "         1.0       1.00      0.95      0.97      1103\n",
      "\n",
      "    accuracy                           0.97      2206\n",
      "   macro avg       0.97      0.97      0.97      2206\n",
      "weighted avg       0.97      0.97      0.97      2206\n",
      "\n",
      "\n",
      "Logistic Regression for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        273    1\n",
      "1.0         16    1\n",
      "\n",
      "Logistic Regression for Ensemble - Test accuracy 0.942\n",
      "\n",
      "Logistic Regression for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97       274\n",
      "         1.0       0.50      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.94       291\n",
      "   macro avg       0.72      0.53      0.54       291\n",
      "weighted avg       0.92      0.94      0.92       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Co-efficients for XGB, DT, RF, AB, LR are: [[ 7.15562608  0.99908828 -1.38781381 -7.62081798  2.69031336]]\n",
      "\n",
      "\n",
      "Ensemble of Models - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        269    5\n",
      "1.0         15    2\n",
      "\n",
      "Ensemble of Models - Test accuracy 0.931\n",
      "\n",
      "Ensemble of Models - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.96       274\n",
      "         1.0       0.29      0.12      0.17        17\n",
      "\n",
      "    accuracy                           0.93       291\n",
      "   macro avg       0.62      0.55      0.57       291\n",
      "weighted avg       0.91      0.93      0.92       291\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------교차검증 번호: 5------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (1164, 178) (1164,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2196, 178) (2196,)\n",
      "SMOTE 적용 후 레이블 값 분포: \n",
      " 1.0    1098\n",
      "0.0    1098\n",
      "dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "XGBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1090     8\n",
      "1.0          35  1063\n",
      "\n",
      "XGBoost for Ensemble - Train accuracy 0.98\n",
      "\n",
      "XGBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      1098\n",
      "         1.0       0.99      0.97      0.98      1098\n",
      "\n",
      "    accuracy                           0.98      2196\n",
      "   macro avg       0.98      0.98      0.98      2196\n",
      "weighted avg       0.98      0.98      0.98      2196\n",
      "\n",
      "\n",
      "XGBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        276    3\n",
      "1.0         11    0\n",
      "\n",
      "XGBoost for Ensemble - Test accuracy 0.952\n",
      "\n",
      "XGBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98       279\n",
      "         1.0       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.95       290\n",
      "   macro avg       0.48      0.49      0.49       290\n",
      "weighted avg       0.93      0.95      0.94       290\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Decision Tree for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted  0.0   1.0\n",
      "Actuall             \n",
      "0.0        659   439\n",
      "1.0         63  1035\n",
      "\n",
      "Decision Tree for Ensemble - Train accuracy 0.771\n",
      "\n",
      "Decision Tree for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.60      0.72      1098\n",
      "         1.0       0.70      0.94      0.80      1098\n",
      "\n",
      "    accuracy                           0.77      2196\n",
      "   macro avg       0.81      0.77      0.76      2196\n",
      "weighted avg       0.81      0.77      0.76      2196\n",
      "\n",
      "\n",
      "Decision Tree for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actual             \n",
      "0.0        153  126\n",
      "1.0          5    6\n",
      "\n",
      "Decision Tree for Ensemble - Test accuracy 0.548\n",
      "\n",
      "Decision Tree for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.55      0.70       279\n",
      "         1.0       0.05      0.55      0.08        11\n",
      "\n",
      "    accuracy                           0.55       290\n",
      "   macro avg       0.51      0.55      0.39       290\n",
      "weighted avg       0.93      0.55      0.68       290\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Random Forest for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1008    90\n",
      "1.0          19  1079\n",
      "\n",
      "Random Forest for Ensemble - Train accuracy 0.95\n",
      "\n",
      "Random Forest for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.92      0.95      1098\n",
      "         1.0       0.92      0.98      0.95      1098\n",
      "\n",
      "    accuracy                           0.95      2196\n",
      "   macro avg       0.95      0.95      0.95      2196\n",
      "weighted avg       0.95      0.95      0.95      2196\n",
      "\n",
      "\n",
      "Random Forest for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        242   37\n",
      "1.0          8    3\n",
      "\n",
      "Random Forest for Ensemble - Test accuracy 0.845\n",
      "\n",
      "Random Forest for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.87      0.91       279\n",
      "         1.0       0.07      0.27      0.12        11\n",
      "\n",
      "    accuracy                           0.84       290\n",
      "   macro avg       0.52      0.57      0.52       290\n",
      "weighted avg       0.93      0.84      0.88       290\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "AdaBoost for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1060    38\n",
      "1.0          56  1042\n",
      "\n",
      "AdaBoost for Ensemble - Train accuracy 0.957\n",
      "\n",
      "AdaBoost for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96      1098\n",
      "         1.0       0.96      0.95      0.96      1098\n",
      "\n",
      "    accuracy                           0.96      2196\n",
      "   macro avg       0.96      0.96      0.96      2196\n",
      "weighted avg       0.96      0.96      0.96      2196\n",
      "\n",
      "\n",
      "AdaBoost for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        267   12\n",
      "1.0         10    1\n",
      "\n",
      "AdaBoost for Ensemble - Test accuracy 0.924\n",
      "\n",
      "AdaBoost for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96       279\n",
      "         1.0       0.08      0.09      0.08        11\n",
      "\n",
      "    accuracy                           0.92       290\n",
      "   macro avg       0.52      0.52      0.52       290\n",
      "weighted avg       0.93      0.92      0.93       290\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression for Ensemble - Train Confusion Matrix\n",
      "\n",
      " Predicted   0.0   1.0\n",
      "Actuall              \n",
      "0.0        1095     3\n",
      "1.0          61  1037\n",
      "\n",
      "Logistic Regression for Ensemble - Train accuracy 0.971\n",
      "\n",
      "Logistic Regression for Ensemble - Train Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      1098\n",
      "         1.0       1.00      0.94      0.97      1098\n",
      "\n",
      "    accuracy                           0.97      2196\n",
      "   macro avg       0.97      0.97      0.97      2196\n",
      "weighted avg       0.97      0.97      0.97      2196\n",
      "\n",
      "\n",
      "Logistic Regression for Ensemble - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        278    1\n",
      "1.0         11    0\n",
      "\n",
      "Logistic Regression for Ensemble - Test accuracy 0.959\n",
      "\n",
      "Logistic Regression for Ensemble - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       279\n",
      "         1.0       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.96       290\n",
      "   macro avg       0.48      0.50      0.49       290\n",
      "weighted avg       0.93      0.96      0.94       290\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Co-efficients for XGB, DT, RF, AB, LR are: [[ 7.13560413  0.21780737 -1.45206826 -7.31900675  3.1226278 ]]\n",
      "\n",
      "\n",
      "Ensemble of Models - Test Confusion Matrix\n",
      "\n",
      " Predicted  0.0  1.0\n",
      "Actuall            \n",
      "0.0        276    3\n",
      "1.0         11    0\n",
      "\n",
      "Ensemble of Models - Test accuracy 0.952\n",
      "\n",
      "Ensemble of Models - Test Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98       279\n",
      "         1.0       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.95       290\n",
      "   macro avg       0.48      0.49      0.49       290\n",
      "weighted avg       0.93      0.95      0.94       290\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "평균 검증 정확도: 0.9359999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "xval = walker_60_f[walker_60_f.columns.difference(['도로심각도지수basic'])]\n",
    "yval = walker_60_f['도로심각도지수basic']\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "\n",
    "\n",
    "\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(xval):\n",
    "    x_train_fold, x_test_fold = xval.iloc[train_index], xval.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = yval.iloc[train_index], yval.iloc[test_index]\n",
    "    \n",
    "    n_iter += 1\n",
    "    print(\"-----------------------------교차검증 번호: {0}------------------------------\".format(n_iter))\n",
    "    x_train_mm, x_test_mm = mmscale(x_train_fold, x_test_fold)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    x_train_over,y_train_over = smt(x_train_mm, y_train_fold)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    clf1_xgb_fit = xgb_f(x_train_over, y_train_over, x_test_mm, y_test_fold)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    clf2_dt_fit = dt_f(x_train_over, y_train_over, x_test_mm, y_test_fold)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    clf3_rf_fit = rf_f(x_train_over, y_train_over, x_test_mm, y_test_fold)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    clf4_adabst_fit = ada_f(x_train_over, y_train_over, x_test_mm, y_test_fold)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    clf5_logreg_fit = lr_f(x_train_over, y_train_over, x_test_mm, y_test_fold)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    ensemble = meta_f1(clf1_xgb_fit, clf2_dt_fit, clf3_rf_fit, clf4_adabst_fit, clf5_logreg_fit, x_train_over, y_train_over)\n",
    "    meta_acc = meta_f2(ensemble, clf1_xgb_fit, clf2_dt_fit, clf3_rf_fit, clf4_adabst_fit, clf5_logreg_fit, x_test_mm, y_test_fold)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    cv_accuracy.append(meta_acc)\n",
    "    \n",
    "print('\\n평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
