{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "walker_60_suwon_origin = pd.read_csv(\"D:\\\\jupyter_proj\\\\walker_60_suwon.csv\")\n",
    "camera = pd.read_csv(\"D:\\\\jupyter_proj\\\\gis_X_suwon_단속카메라.csv\")\n",
    "pro_cas = pd.read_csv(\"D:\\\\jupyter_proj\\\\사고건수_도로위험도.csv\")\n",
    "\n",
    "walker_60_suwon_origin = walker_60_suwon_origin[walker_60_suwon_origin.columns.difference(['도로심각도지수basic'])]\n",
    "\n",
    "walker_60_suwon = pd.concat([walker_60_suwon_origin, camera],axis=1)\n",
    "walker_60_suwon = walker_60_suwon.drop([\"field_1\",'Unnamed: 0'], axis=1)\n",
    "walker_60_suwon = pd.concat([walker_60_suwon, pro_cas],axis=1)\n",
    "walker_60_suwon = walker_60_suwon.drop([\"field_1\",'사고건수'], axis=1)\n",
    "\n",
    "walker_60_suwon.rename(columns={'도로위험도':'도로심각도지수basic'}, inplace=True)\n",
    "\n",
    "Q1 = walker_60_suwon['도로심각도지수basic'].quantile(.25)\n",
    "Q3 = walker_60_suwon['도로심각도지수basic'].quantile(.75)\n",
    "Q2 = walker_60_suwon['도로심각도지수basic'].quantile(.5)\n",
    "Q4 = walker_60_suwon['도로심각도지수basic'].quantile(1)\n",
    "\n",
    "print(\"Q1 =\",Q1)\n",
    "print(\"Q2 =\",Q2)\n",
    "print(\"Q3 =\",Q3)\n",
    "print(\"Q4 =\",Q4)\n",
    "\n",
    "print(np.mean(walker_60_suwon['도로심각도지수basic']))\n",
    "\n",
    "plt.boxplot(walker_60_suwon['도로심각도지수basic'])\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(walker_60_suwon)):\n",
    "    if walker_60_suwon['도로심각도지수basic'][i] <= 0.1168:\n",
    "        walker_60_suwon['도로심각도지수basic'][i] = 0\n",
    "    else:\n",
    "        walker_60_suwon['도로심각도지수basic'][i] = 1\n",
    "        \n",
    "plt.hist(walker_60_suwon['도로심각도지수basic'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_가해자성별 = pd.get_dummies(walker_60_suwon['가해자성별'], prefix='가해자성별')\n",
    "dummy_교차로형태 = pd.get_dummies(walker_60_suwon['교차로형태'], prefix='교차로형태')\n",
    "dummy_기상상태 = pd.get_dummies(walker_60_suwon['기상상태'], prefix='기상상태')\n",
    "dummy_노면상태 = pd.get_dummies(walker_60_suwon['노면상태'], prefix='노면상태')\n",
    "dummy_노면상태_대분류 = pd.get_dummies(walker_60_suwon['노면상태_대분류'], prefix='노면상태_대분류')\n",
    "dummy_노인보호구역 = pd.get_dummies(walker_60_suwon['노인보호구역'], prefix='노인보호구역')\n",
    "dummy_당사자종별가해자 = pd.get_dummies(walker_60_suwon['당사자종별가해자'], prefix='당사자종별가해자')\n",
    "dummy_당사자종별피해자 = pd.get_dummies(walker_60_suwon['당사자종별피해자'], prefix='당사자종별피해자')\n",
    "dummy_도로선형 = pd.get_dummies(walker_60_suwon['도로선형'], prefix='도로선형')\n",
    "dummy_도로선형_대분류 = pd.get_dummies(walker_60_suwon['도로선형_대분류'], prefix='도로선형_대분류')\n",
    "dummy_도로선형_중분류 = pd.get_dummies(walker_60_suwon['도로선형_중분류'], prefix='도로선형_중분류')\n",
    "dummy_도로종류 = pd.get_dummies(walker_60_suwon['도로종류'], prefix='도로종류')\n",
    "dummy_도로형태 = pd.get_dummies(walker_60_suwon['도로형태'], prefix='도로형태')\n",
    "dummy_법규위반가해자 = pd.get_dummies(walker_60_suwon['법규위반가해자'], prefix='법규위반가해자')\n",
    "dummy_보호장구가해자_대분류 = pd.get_dummies(walker_60_suwon['보호장구가해자_대분류'], prefix='보호장구가해자_대분류')\n",
    "dummy_보호장구피해자_대분류 = pd.get_dummies(walker_60_suwon['보호장구피해자_대분류'], prefix='보호장구피해자_대분류')\n",
    "dummy_사고유형 = pd.get_dummies(walker_60_suwon['사고유형'], prefix='사고유형')\n",
    "dummy_사고유형_대분류 = pd.get_dummies(walker_60_suwon['사고유형_대분류'], prefix='사고유형_대분류')\n",
    "dummy_어린이보호구역 = pd.get_dummies(walker_60_suwon['어린이보호구역'], prefix='어린이보호구역')\n",
    "dummy_요일 = pd.get_dummies(walker_60_suwon['요일'], prefix='요일')\n",
    "dummy_주야 = pd.get_dummies(walker_60_suwon['주야'], prefix='주야')\n",
    "dummy_차량용도가해자 = pd.get_dummies(walker_60_suwon['차량용도가해자'], prefix='차량용도가해자')\n",
    "dummy_차량용도가해자_대분류 = pd.get_dummies(walker_60_suwon['차량용도가해자_대분류'], prefix='차량용도가해자_대분류')\n",
    "dummy_차량용도피해자 = pd.get_dummies(walker_60_suwon['차량용도피해자'], prefix='차량용도피해자')\n",
    "dummy_차량용도피해자_대분류 = pd.get_dummies(walker_60_suwon['차량용도피해자_대분류'], prefix='차량용도피해자_대분류')\n",
    "dummy_피해자성별 = pd.get_dummies(walker_60_suwon['피해자성별'], prefix='피해자성별')\n",
    "dummy_행동유형가해자 = pd.get_dummies(walker_60_suwon['행동유형가해자'], prefix='행동유형가해자')\n",
    "dummy_행동유형피해자 = pd.get_dummies(walker_60_suwon['행동유형피해자'], prefix='행동유형피해자')\n",
    "dummy_행동유형피해자_대분류 = pd.get_dummies(walker_60_suwon['행동유형피해자_대분류'], prefix='행동유형피해자_대분류')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continues_cols = ['연령가해자','연령피해자','제한속도_평균','제한속도_최대','단속카메라수']\n",
    "walker_60_continues = walker_60_suwon[continues_cols]\n",
    "\n",
    "walker_60_f = pd.concat([dummy_가해자성별, dummy_교차로형태, dummy_기상상태, dummy_노면상태, dummy_노면상태_대분류, dummy_노인보호구역, \n",
    "                        dummy_당사자종별가해자, dummy_당사자종별피해자, dummy_도로선형, dummy_도로선형_대분류, dummy_도로선형_중분류, \n",
    "                        dummy_도로종류, dummy_도로형태, dummy_법규위반가해자, dummy_보호장구가해자_대분류, \n",
    "                        dummy_보호장구피해자_대분류, dummy_사고유형, dummy_사고유형_대분류, dummy_어린이보호구역, dummy_요일, \n",
    "                        dummy_주야,dummy_차량용도가해자, dummy_차량용도가해자_대분류, dummy_차량용도피해자, dummy_차량용도피해자_대분류,\n",
    "                        dummy_피해자성별, dummy_행동유형가해자, dummy_행동유형피해자, dummy_행동유형피해자_대분류,walker_60_continues, \n",
    "                        walker_60_suwon['도로심각도지수basic']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmscale(x_train, x_test):\n",
    "\n",
    "    x_train['연령피해자'] = (x_train['연령피해자'] - x_train['연령피해자'].min(axis=0)) / (x_train['연령피해자'].max(axis=0) - x_train['연령피해자'].min(axis=0))\n",
    "    x_train['연령가해자'] = (x_train['연령가해자'] - x_train['연령가해자'].min(axis=0)) / (x_train['연령가해자'].max(axis=0) - x_train['연령가해자'].min(axis=0))\n",
    "\n",
    "    x_test['연령피해자'] = (x_test['연령피해자'] - x_test['연령피해자'].min(axis=0)) / (x_test['연령피해자'].max(axis=0) - x_test['연령피해자'].min(axis=0))\n",
    "    x_test['연령가해자'] = (x_test['연령가해자'] - x_test['연령가해자'].min(axis=0)) / (x_test['연령가해자'].max(axis=0) - x_test['연령가해자'].min(axis=0))\n",
    "    \n",
    "    x_train['제한속도_평균'] = (x_train['제한속도_평균'] - x_train['제한속도_평균'].min(axis=0)) / (x_train['제한속도_평균'].max(axis=0) - x_train['제한속도_평균'].min(axis=0))\n",
    "    x_train['제한속도_최대'] = (x_train['제한속도_최대'] - x_train['제한속도_최대'].min(axis=0)) / (x_train['제한속도_최대'].max(axis=0) - x_train['제한속도_최대'].min(axis=0))\n",
    "    x_train['단속카메라수'] = (x_train['단속카메라수'] - x_train['단속카메라수'].min(axis=0)) / (x_train['단속카메라수'].max(axis=0) - x_train['단속카메라수'].min(axis=0))\n",
    "    \n",
    "    x_test['제한속도_평균'] = (x_test['제한속도_평균'] - x_test['제한속도_평균'].min(axis=0)) / (x_test['제한속도_평균'].max(axis=0) - x_test['제한속도_평균'].min(axis=0))\n",
    "    x_test['제한속도_최대'] = (x_test['제한속도_최대'] - x_test['제한속도_최대'].min(axis=0)) / (x_test['제한속도_최대'].max(axis=0) - x_test['제한속도_최대'].min(axis=0))\n",
    "    x_test['단속카메라수'] = (x_test['단속카메라수'] - x_test['단속카메라수'].min(axis=0)) / (x_test['단속카메라수'].max(axis=0) - x_test['단속카메라수'].min(axis=0))\n",
    "    \n",
    "    x_train_mm = x_train\n",
    "    x_test_mm = x_test\n",
    "\n",
    "    return x_train_mm, x_test_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smt(x_train, y_train):\n",
    "    smote = SMOTE(random_state=97)\n",
    "    \n",
    "    x_train_over,y_train_over = smote.fit_sample(x_train,list(y_train))\n",
    "    y_train_over = np.array(y_train_over)\n",
    "    print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, (np.array(y_train)).shape)\n",
    "    print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', x_train_over.shape, y_train_over.shape)\n",
    "    print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())\n",
    "    \n",
    "    return x_train_over,y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_f(x_train_over, y_train_over, x_test, y_test):\n",
    "    clf3_rf_fit = RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=8, min_samples_split=2, min_samples_leaf=1)\n",
    "    clf3_rf_fit.fit(x_train_over, y_train_over)\n",
    "\n",
    "    print(\"\\nRandom Forest for Ensemble - Train Confusion Matrix\\n\\n\", pd.crosstab(y_train_over, clf3_rf_fit.predict(x_train_over), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nRandom Forest for Ensemble - Train accuracy\", round(accuracy_score(y_train_over, clf3_rf_fit.predict(x_train_over)),3))\n",
    "    print(\"\\nRandom Forest for Ensemble - Train Classification Report\\n\", classification_report(y_train_over, clf3_rf_fit.predict(x_train_over)))\n",
    "\n",
    "    print(\"\\nRandom Forest for Ensemble - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, clf3_rf_fit.predict(x_test), rownames=[\"Actuall\"], colnames=[\"Predicted\"]))\n",
    "    print(\"\\nRandom Forest for Ensemble - Test accuracy\", round(accuracy_score(y_test, clf3_rf_fit.predict(x_test)),3))\n",
    "    print(\"\\nRandom Forest for Ensemble - Test Classification Report\\n\", classification_report(y_test, clf3_rf_fit.predict(x_test)))\n",
    "    \n",
    "    model_ranks = pd.Series(clf3_rf_fit.feature_importances_, index=x_train_over.columns).sort_values(ascending=False, inplace=False)\n",
    "    model_ranks.index.name = 'Variables'\n",
    "    \n",
    "    top_features = model_ranks.iloc[:31].sort_values(ascending=True, inplace=False)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    ax = top_features.plot(kind='barh')\n",
    "    _ = ax.set_title(\"Variable Importance Plot\")\n",
    "    _ = ax.set_xlabel('Mean decrease in Variane')\n",
    "    _ = ax.set_yticklabels(top_features.index, fontsize=13)\n",
    "    plt.show()\n",
    "    \n",
    "    return clf3_rf_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "walker_60_f.to_csv(\"pre_final.csv\")\n",
    "xval = walker_60_f[walker_60_f.columns.difference(['도로심각도지수basic'])]\n",
    "yval = walker_60_f['도로심각도지수basic']\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "\n",
    "\n",
    "\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(xval):\n",
    "    x_train_fold, x_test_fold = xval.iloc[train_index], xval.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = yval.iloc[train_index], yval.iloc[test_index]\n",
    "    \n",
    "    n_iter += 1\n",
    "    print(\"-----------------------------교차검증 번호: {0}------------------------------\".format(n_iter))\n",
    "    x_train_mm, x_test_mm = mmscale(x_train_fold, x_test_fold)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    x_train_over,y_train_over = smt(x_train_mm, y_train_fold)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    clf3_rf_fit = rf_f(x_train_over, y_train_over, x_test_mm, y_test_fold)\n",
    "    print(\"-\" * 80)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
